{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain langchain-anthropic duckduckgo-search langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain Tool Calling is a great way to connect your LLM to the information that LLM doesn\\'t have, i.e to connect your LLM with the real world, the world that is still working and updating itself daily, making LangChain tool calling an essential tool for us to use with LLM. LangChain provides standard Tool Calling approach to many LLM providers like Anthropic, Cohere, Google, Mistral, and OpenAI support variants of this tool calling feature. bind_tools method What is a tool calling agent ? simply put a chain of langChain components(LLM, Tools, Propmt, Parsers) that utilize the LLM to repeatedly call itself in a loop. \"Chains are great when we know theâ€¦ Learn how to use tool calling functionality with various LLM providers that expose API\\'s for reliable tool invocation. See the standard interface for attaching tool definitions, accessing tool calls, and creating tool calling agents with LangChain. Tool calling is a standout feature in agentic design, allowing the LLM to interact with external systems or perform specific tasks via the @tool decorator. This adds significant flexibility ...'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "search.invoke(\"What is LangChain Tool Calling?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Tool for sending Slack messages using a webhook\n",
    "import requests\n",
    "import json\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "@tool\n",
    "def send_slack_message(message: str) -> str:\n",
    "    \"\"\"\n",
    "    Sends a message to a Slack app using Slack webhook.\n",
    "\n",
    "    Args:\n",
    "        message (str): The message to send.\n",
    "\n",
    "    Returns:\n",
    "        str: A success or error message.\n",
    "    \"\"\"\n",
    "    webhook_url = \"https://YOUR_SLACK_WEBHOOK_URL\"\n",
    "    payload = {\"text\": message}\n",
    "    headers = {\"Content-type\": \"application/json\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(webhook_url, data=json.dumps(payload), headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return \"Message sent successfully!\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error sending message: {e}\"\n",
    "\n",
    "message = \"Hello from Claude!\"\n",
    "send_slack_message.invoke({\"message\": message})\n",
    "# 'Message sent successfully!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "# take environment variables from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# ChatAnthropic - Claude 3 Haiku\n",
    "llm = ChatAnthropic(model = \"claude-3-haiku-20240307\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools\n",
    "tools = [search, send_slack_message]\n",
    "\n",
    "# llm with tools\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"What is LangChain Tool Calling?\")\n",
    "]\n",
    "\n",
    "llm_with_tools.invoke(messages).tool_calls\n",
    "#[{'name': 'duckduckgo_search',\n",
    "#  'args': {'query': 'LangChain Tool Calling'},\n",
    "#  'id': 'toolu_01Bfrz1Uhu84ggZd96Ae9De8'}]\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"Send 'ðŸ‘‹ Happy Birthday from Claude! ðŸ˜ƒ' message to Slack app.\")\n",
    "]\n",
    "\n",
    "llm_with_tools.invoke(messages).tool_calls\n",
    "#[{'name': 'send_slack_message',\n",
    "#  'args': {'message': 'ðŸ‘‹ Happy Birthday from Claude! ðŸ˜ƒ'},\n",
    "#  'id': 'toolu_01LKxZvHpmDrdLooo1aJWqum'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"Send 'ðŸ‘‹ Happy Birthday from Claude! ðŸ˜ƒ' message to Slack app.\")\n",
    "]\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"duckduckgo_search\": search, \"send_slack_message\": send_slack_message}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "\n",
    "messages\n",
    "#[('system', 'You are a helpful assistant.'),\n",
    "#  ('human', \"Send 'ðŸ‘‹ Happy Birthday from Claude! ðŸ˜ƒ' message to Slack app.\"),\n",
    "#  AIMessage(content=[{'id': 'toolu_01HAV1YsmhUWK4ZRc8FJf7cL', 'input': {'message': 'ðŸ‘‹ Happy Birthday from Claude! ðŸ˜ƒ'}, 'name': 'send_slack_message', 'type': 'tool_use'}], response_metadata={'id': 'msg_01J59CnLZws1JngV9atfKwz9', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 499, 'output_tokens': 65}}, id='run-c9eb80b8-1b94-4e96-95a9-76f9f0c45c78-0', tool_calls=[{'name': 'send_slack_message', 'args': {'message': 'ðŸ‘‹ Happy Birthday from Claude! ðŸ˜ƒ'}, 'id': 'toolu_01HAV1YsmhUWK4ZRc8FJf7cL'}]),\n",
    "#  ToolMessage(content='Message sent successfully!', tool_call_id='toolu_01HAV1YsmhUWK4ZRc8FJf7cL')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Prompt for creating Tool Calling Agent\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Construct the Tool Calling Agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Run Agent\n",
    "query = \"What is LangChain Tool Calling Agent? Please send it to Slack app.\"\n",
    "agent_executor.invoke({\"input\": query})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inforet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
